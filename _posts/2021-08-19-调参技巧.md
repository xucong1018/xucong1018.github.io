# 调参技巧

- Learning Rate设置合理

❓ 太大: loss爆炸, 或者nan；太小，训练不动


- 自动调参方法

❓ Grid Search：遍历所有候选的参数，速度慢
Random Search：随机搜索所有候选的参数


- 注意loss的范围

❓ 多任务情况下, 各loss限制在一个量级上


- 激活函数选择

❓ 对于输出层，多分类任务选用softmax输出，二分类任务选用sigmoid输出，回归任务选用线性输出。而对于中间隐层，则优先选择relu激活函数


- 好的优化器

❓ 一般使用自适应的优化器，如Adam

