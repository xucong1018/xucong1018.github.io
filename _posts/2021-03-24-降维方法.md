---
layout:     post
title:      降维方法
subtitle:   降维方法简介
date:       2021-03-24
author:     Cong
header-img: img/post-bg-cook.jpg
catalog: true
tags:
    - 降维方法
---




# 降维方法

## **PCA、LDA**

[机器学习（五）：数据预处理--降维-PCA和LDA](https://zhuanlan.zhihu.com/p/111631197)

[ML中的数据降维算法：PCA&LDA](https://zhuanlan.zhihu.com/p/93428776)

![Untitled](%E9%99%8D%E7%BB%B4%E6%96%B9%E6%B3%95%2095a8914f07de467199c9c4da016498fd/Untitled.png)

💡 **LDA与PCA比较**

**相同点：**

- 两者均可以对数据进行降维
两者在降维时均使用了矩阵特征分解的思想。
两者都假设数据符合高斯分布

**不同点：**

- LDA是有监督的降维方法，而PCA是无监督的降维方法
- LDA除了可以用于降维，还可以用于分类
- LDA降维最多降到**类别数K-1**的维数，而PCA没有这个限制
- LDA选择**分类性能最好**的投影方向，而PCA选择样本点投影具有**最大方差**的方向。

💡 **LDA优缺点：**

**优点：**

- LDA在样本分类信息依赖均值而不是方差的时候，比PCA分类的算法更优
- 在降维过程中可以使用类别的先验知识经验，

**缺点：**

- LDA与PCA都不适合对非高斯分布的样本进行降维
- LDA降维最多降到类别数K-1的维数
- LDA在样本分类信息依赖方差而不是均值的时候降维效果不好。
- LDA可能过度拟合数据。
