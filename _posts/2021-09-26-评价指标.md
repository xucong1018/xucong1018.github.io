# 评价指标

# 分类

[分类问题的评估指标一览](https://zhuanlan.zhihu.com/p/69101372)

- TP： True Positives， 表示**实际为正例**且被分类器**判定为正例**的样本数
- FP： False Positives， 表示**实际为负例**且被分类器**判定为正例**的样本数
- FN： False Negatives， 表示**实际为正例**但被分类器**判定为负例**的样本数
- TN： True Negatives， 表示**实际为负例**且被分类器**判定为负例**的样本数

---

![Untitled](https://github.com/xucong1018/xucong1018.github.io/blob/master/img/评价指标/Untitled.png?raw=true)

![Untitled](https://github.com/xucong1018/xucong1018.github.io/blob/master/img/评价指标/Untitled%201.png?raw=true)

![Untitled](https://github.com/xucong1018/xucong1018.github.io/blob/master/img/评价指标/Untitled%202.png?raw=true)

---

## F1

![Untitled](https://github.com/xucong1018/xucong1018.github.io/blob/master/img/评价指标/Untitled%203.png?raw=true)

![Untitled](https://github.com/xucong1018/xucong1018.github.io/blob/master/img/评价指标/Untitled%204.png?raw=true)

### **Macro F1**

**Macro 算法在计算 Precision 与 Recall 时是先分别计算每个类别的Precision 与 Recall**， 然后再进行平均。

![Untitled](https://github.com/xucong1018/xucong1018.github.io/blob/master/img/评价指标/Untitled%205.png?raw=true)

![Untitled](https://github.com/xucong1018/xucong1018.github.io/blob/master/img/评价指标/Untitled%206.png?raw=true)

![Untitled](https://github.com/xucong1018/xucong1018.github.io/blob/master/img/评价指标/Untitled%207.png?raw=true)

![Untitled](https://github.com/xucong1018/xucong1018.github.io/blob/master/img/评价指标/Untitled%208.png?raw=true)

![Untitled](https://github.com/xucong1018/xucong1018.github.io/blob/master/img/评价指标/Untitled%209.png?raw=true)

### **Micro**

**Micro 算法计算全局的 Precision 与 Recall 。**

![Untitled](https://github.com/xucong1018/xucong1018.github.io/blob/master/img/评价指标/Untitled%2010.png?raw=true)

![Untitled](https://github.com/xucong1018/xucong1018.github.io/blob/master/img/评价指标/Untitled%2011.png?raw=true)

![Untitled](https://github.com/xucong1018/xucong1018.github.io/blob/master/img/评价指标/Untitled%2012.png?raw=true)

- **Macro 相对 Micro 而言，小类别起到的作用更大，**
- **Macro单纯的平均忽略了样本之间分布可能存在极大不平衡的情况**
- 如果 Micro << Macro ， 则意味着在大样本类别中出现了严重的分类错误； 如果 Macro << Micro ， 则意味着小样本类别中出现了严重的分类错误。

---

## MCC

MCC 主要用于衡量二分类问题，其综合考虑了 TP TN, FP , FN， **是一个比较均衡的指标， 对于样本不均衡情况下也可以使用**。MCC的取值范围在 **[-1, 1]**， 取值为1 表示预测与实际完全一致，

![Untitled](https://github.com/xucong1018/xucong1018.github.io/blob/master/img/评价指标/Untitled%2013.png?raw=true)

---

## AUC

[机器学习篇-指标:AUC_菜鸟教程*...*的博客-CSDN博客_auc指标](https://blog.csdn.net/fanfangyu/article/details/122885441?raw=true)

### **ROC曲线（受试者工作特征）**

在分类任务中，往往会采取一个阈值，大于该阈值的为正例， 小于该阈值的为负例。 如果我们减小这个阈值， 那么会有更多的样本被识别为正类，这会提高正类的识别率，但同时会降低负类的识别率。

为了形象的描述上述的这种变化， 引入ROC曲线来评价一个分类器的好坏。 ROC 曲线主要关注两个指标：

![Untitled](https://github.com/xucong1018/xucong1018.github.io/blob/master/img/评价指标/Untitled%2014.png?raw=true)

![Untitled](https://github.com/xucong1018/xucong1018.github.io/blob/master/img/评价指标/Untitled%2015.png?raw=true)

![Untitled](https://github.com/xucong1018/xucong1018.github.io/blob/master/img/评价指标/Untitled%2016.png?raw=true)

### ****曲线下面积（AUC）****

**随机抽取一个阳性样本和一个阴性样，P1为将正样本预测为正样本概率，P2为将负样本预测为正样本概率，AUC为P1>P2的概率。**

💡 **计算**

> 对一批已知正负的样本集合进行分类，按照预测概率**从低到高进行排序**，
> 

> 对于正样本中概率最高的，排序为rank_1，比它概率小的有M-1个正样本（M为正样本个数），（ranl_1-M）个负样本。
正样本中概率第二高的，排序为rank_2，比它概率小的有M-2个正样本，（rank_2-(M-1)）个负样本，
以此类推，正样本中概率最小的，排序为rank_M，比它概率小的有0个正样本，(rank_M-1)个负样本。
> 

> 总共有M*N个正负样本对，把所有比较中正样本概率大于负样本概率的例子都算上，*
> 

$$
\left(\operatorname{rank}_{1}-M+\operatorname{rank}_{2}-(M-1)+\ldots+\operatorname{rank}_{M}-1\right) /(M * N)\\AUC=\frac{\sum_{\mathrm{i} \in \text { positive }} \operatorname{rank}_{i}-\frac{M(1+M)}{2}}{M \times N}
$$


**优点：**

- AUC反映的是分类器对样本的**排序能力**，适合排序问题
- AUC对**样本类别均衡**并不敏感
- AUC不需要**⼿动设定阈值**，是⼀种整体上的衡量⽅法。

**缺点：**

- 忽略预测概率和模型的**拟合优度**
- **信息笼统**，不能反映召回率、精确率等实际业务中关⼼的指标
- **类别内部没有比较**，⽆法衡量样本对于分类好坏程度的刻画能⼒

---

## PR曲线

P-R 曲线其横坐标为 Recall， 纵坐标为 Precision， 其能帮助我们很好的做出权衡

![A覆盖C，A优于C](https://github.com/xucong1018/xucong1018.github.io/blob/master/img/评价指标/Untitled%2017.png?raw=true)

A覆盖C，A优于C

P-R曲线肯定会经过（0,0）点（**与y轴重合**），所有的样本全部判为负例

---

## G-mean

G-mean = Precision1*Precision0，评估不平衡数据集。

![Untitled](https://github.com/xucong1018/xucong1018.github.io/blob/master/img/评价指标/Untitled%2018.png?raw=true)

---

# 推荐系统****离线评估指标****

## ****评分预测指标****

符号定义：对于测试集中的一个用户$u$和物品$i$，令$r_{ui}$是用户$u$对物品$i$的实际评分，而$\hat{r}_{ui}$是推荐算法给出的预测评分。

- **均方根误差(Root Mean Squared Error，RMSE)**

$$
\operatorname{RMSE}=\frac{\sqrt{\sum_{u, i \in T}\left(r_{u i}-\hat{r}_{u i}\right)^{2}}}{|T|}
$$

- ****平均绝对误差(Mean Absolute Error，MAE)****

$$
\mathrm{MAE}=\frac{\sum_{u, i \in T}\left|r_{u i}-\hat{r}_{u i}\right|}{|T|}
$$

## ****TopN推荐****

符号定义：用户集合为$U$，物品列表$I$，$R(u)$代表根据用户在训练集上的行为给用户做出的推荐列表，$T(u)$代表用户在测试集上的行为列表。

- ****精确度(Precision)：****即推荐准确的数量，除以推荐列表的总数，通俗讲就是推荐的准确率。

$$
\text { Precision }=\frac{\sum_{u \in U}|R(u) \cap T(u)|}{\sum_{u \in U}|R(u)|}
$$

- ****召回率(Recall)：****准确推荐的数目与用户的行为总数目的比值，一定程度上表示了对推荐潜力的挖掘程度。

$$
\text { Recall }=\frac{\sum_{u \in U}|R(u) \cap T(u)|}{\sum_{u \in U}|T(u)|}
$$

- **Hit Ratio(HR)：**在top-K推荐中，HR是一种常用的衡量召回率的指标

$$
HR@K=\frac{NumberOfHits@K}{GT}
$$

- **覆盖率(Coverage)：**覆盖率表示推荐系统能够推荐出来的物品占总物品集合的比例，它描述一个推荐系统对物品**长尾**的发掘能力（**不忽略冷门商品**）。

$$
\text { Coverage }=\frac{\left|\bigcup_{\mathrm{u} \in \mathrm{U}} \mathrm{R}(\mathrm{u})\right|} {|I|}
$$

- **多样性：**假设$s(i,j)∈[0,1]$定义了物品$i$和$j$之间的相似度，

$$
\begin{aligned}Diversity(u)&=1-\frac{\sum_{i, j \in R(u)} s(i, j)}{\frac{1}{2} \mid R(u)(|R(u)|-1)} \quad  \\Diversity &=\frac{1}{|U|} \sum_{u \in U} \operatorname{Diversity}(u)\end{aligned}
$$